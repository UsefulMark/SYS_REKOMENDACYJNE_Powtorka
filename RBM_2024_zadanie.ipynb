{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a28426c",
   "metadata": {},
   "source": [
    "Stwórz funkcję o nazwie 'Bernoullie', przyjmującą jeden parameter 'p', floata z przedziału od 0 do 1.\n",
    "Funkcja ma realziwoać rozkład zero-jedynkowy, czyli zwracać wartość 1 z prawdopodbieństwem 'p', a 0 z prawdopodobieństwem '1-p'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Bernoullie(p):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4fb69",
   "metadata": {},
   "source": [
    "Sprawdź czy funkcja działa zgodnie z oczekiwaniami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ca30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ile = 5000\n",
    "sum([Bernoullie(0.2) for i in range(ile)])/ile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99470f38",
   "metadata": {},
   "source": [
    "Stwórz klasę RBM, która ma implementować Ograniczoną Maszynę Boltzmanna. Konstuktor powineine przyjąć dwa parametry 'no_v' i 'no_h' określające odpowiednio liczbę neuronów w warstwie widocznej i ukrytej. Zaininciuj odpowiednie wagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        self.wagi = np.random.random((no_v, no_h))\n",
    "        self.b = np.random.random(no_v)\n",
    "        self.c = np.random.random(no_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee78fd2",
   "metadata": {},
   "source": [
    "Napisz metodę aktywacji warstwy ukrytej 'activate_hidden_layer'. Metoda na wejście ma przyjmować wartości tablicę warstwy widocznej 'v'. Meotda ma zwracać tablicę realizacji aktywacji neuronów warstwy ukrytej oraz tablicę prawdopodobieństw tej aktywacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        pass\n",
    "        \n",
    "    def activate_hidden_layer(self, v):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68219baa",
   "metadata": {},
   "source": [
    "Napisz analogiczną metodę do aktywacji warstwy widocznej 'activate_visible_layer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    pass\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        pass\n",
    "    \n",
    "    def activate_hidden_layer(self, v):\n",
    "        pass\n",
    "\n",
    "    def activate_visible_layer(self, h):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab88425",
   "metadata": {},
   "source": [
    "Sprawdź czy warstwy działają tak jak tego oczekujemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecce23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RBM(3,2)\n",
    "model.activate_hidden_layer([1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8dd217",
   "metadata": {},
   "source": [
    "Napisz metodę rezalizującą metodę contrastive divergence. Metoda ma jako parametry przyjmować zbiór elementów (mini-batch) oznaczony X oraz liczbę iteracji algorytmu (k). Metoda ma zwracać 6 wartości. Mają to być odpowiednio dla  tablicy wag, biasu warstwy widocznej i biasu warstwy ukrytej wartości 'E_data' oraz 'E_recon'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        pass\n",
    "    \n",
    "    def activate_hidden_layer(self, v):\n",
    "        pass\n",
    "\n",
    "    def activate_visible_layer(self, h):\n",
    "        pass\n",
    "    \n",
    "    def CD(self, X, k=1):\n",
    "\n",
    "        return E_data, E_recon, E_bv_data, E_bv_recon, E_bh_data, E_bh_recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05a695",
   "metadata": {},
   "source": [
    "Napisz metodę fit realziujacą uczenie metodą spadku gradientu metodą mini-batchową, gdzie gradienty są liczone metodą contrastive divergency (CD). Metoda ma przyjmować parametry: zbiór uczący (X), liczba epok (epochs), wielkość mini-batcha (bs), liczba iteracji dla CD (k) oraz współczynnik uczenia (lr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        pass\n",
    "    \n",
    "    def activate_hidden_layer(self, v):\n",
    "        pass\n",
    "\n",
    "    def activate_visible_layer(self, h):\n",
    "        pass\n",
    "    \n",
    "    def CD(self, X, k=1):\n",
    "        pass\n",
    "        return E_data, E_recon, E_bv_data, E_bv_recon, E_bh_data, E_bh_recon\n",
    "\n",
    "    def fit(self, X, epochs = 10, bs = 10, k=1, lr=0.01):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cf059",
   "metadata": {},
   "source": [
    "Napisz metodę obliczającą błąd rekonstrukcji 'recreate_error'. Metoda ma przyjmować jako parametr tablicę danych. Dla kolejnych elementów z tablicy ma być obliczana ich ukryta reprezentacja, a następnie na tej podstawie ma być ten element odtworzony przez sieć. \n",
    "Metoda ma zwracać błąd absolutny odtworzenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        pass\n",
    "    \n",
    "    def activate_hidden_layer(self, v):\n",
    "        pass\n",
    "\n",
    "    def activate_visible_layer(self, h):\n",
    "        pass\n",
    "    \n",
    "    def CD(self, X, k=1):\n",
    "        pass\n",
    "        return E_data, E_recon, E_bv_data, E_bv_recon, E_bh_data, E_bh_recon\n",
    "\n",
    "    def fit(self, X, epochs = 10, bs = 10, k=1, lr=0.01):\n",
    "        pass\n",
    "    \n",
    "    def recreate_error(self, X):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2db20",
   "metadata": {},
   "source": [
    "Wczytaj dane ze zbioru MNIST. Możesz to zrobić używając polecenia:\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "Następnie przetrasformuj dane tak, aby piksele były zakodowane jako wartości 0 lub 1 (np. użyj testu piksel>128). \n",
    "Wyświetl kilka obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca790a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X, Y), (Xt, Yt) = mnist.load_data()\n",
    "\n",
    "X = X.reshape((X.shape[0], 28*28))\n",
    "X = np.asarray(X, dtype=float)\n",
    "Xt = Xt.reshape((Xt.shape[0], 28*28))\n",
    "Xt = np.asarray(Xt, dtype=float)\n",
    "X /= 255\n",
    "Xt /= 255\n",
    "X[X > 0.5] = 1\n",
    "X[X <= 0.5] = 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    j = np.random.randint(len(X))\n",
    "    plt.imshow(X[j].reshape((28,28)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e09e4",
   "metadata": {},
   "source": [
    "Utwórz model i naucz go na przygotowanych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RBM(28*28, 100)\n",
    "model.fit(X, 10, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92db1b7",
   "metadata": {},
   "source": [
    "Wyświetl koło siebie kilka przykładów obrazów ze zbioru danych i odtworzonych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 3\n",
    "k=0\n",
    "for i in np.random.randint(0,len(X), j):\n",
    "  plt.subplot(j, 2, k*2+1)\n",
    "  x, _ = model.activate_hidden(X[i])\n",
    "  x, _ = model.activate_visible(x)\n",
    "  x = x.reshape((28, 28))\n",
    "  plt.imshow(x)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.subplot(j, 2, k*2+2)\n",
    "  plt.imshow(X[i].reshape((28,28)))\n",
    "  k += 1\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b603a",
   "metadata": {},
   "source": [
    "RBM_2024 komentarz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31862c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Funkcja aktywacji sigmoid: przekształca dowolną wartość na zakres [0, 1]\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Klasa RBM (Restricted Boltzmann Machine)\n",
    "class RBM:\n",
    "    def __init__(self, no_v, no_h):\n",
    "        \"\"\"\n",
    "        Inicjalizuje RBM z podaną liczbą neuronów w warstwach widocznej (no_v) i ukrytej (no_h).\n",
    "        \"\"\"\n",
    "        self.no_v = no_v  # Liczba neuronów w warstwie widocznej\n",
    "        self.no_h = no_h  # Liczba neuronów w warstwie ukrytej\n",
    "        self.W = np.random.normal(0, 0.01, (no_v, no_h))  # Losowe inicjalizowanie wag z rozkładu normalnego\n",
    "        self.bias_v = np.random.normal(0, 1, no_v) * 0.1  # Biasy dla warstwy widocznej\n",
    "        self.bias_h = np.random.normal(0, 1, no_h) * 0.1  # Biasy dla warstwy ukrytej\n",
    "\n",
    "    def activate_hidden(self, v):\n",
    "        \"\"\"\n",
    "        Oblicza aktywację warstwy ukrytej na podstawie danych z warstwy widocznej.\n",
    "        \"\"\"\n",
    "        prawdo = sigmoid(np.matmul(v, self.W) + self.bias_h)  # Prawdopodobieństwa aktywacji ukrytej\n",
    "        act = np.asarray(np.random.random(self.no_h) < prawdo, dtype=int)  # Binarny sampling aktywacji\n",
    "        return act, prawdo\n",
    "\n",
    "    def activate_visible(self, h):\n",
    "        \"\"\"\n",
    "        Oblicza aktywację warstwy widocznej na podstawie danych z warstwy ukrytej.\n",
    "        \"\"\"\n",
    "        prawdo = sigmoid(np.matmul(h, self.W.T) + self.bias_v)  # Prawdopodobieństwa aktywacji widocznej\n",
    "        act = np.asarray(np.random.random(self.no_v) < prawdo, dtype=int)  # Binarny sampling aktywacji\n",
    "        return act, prawdo\n",
    "\n",
    "    def CD(self, X, k=1):\n",
    "        \"\"\"\n",
    "        Wykonuje Contrastive Divergence w celu uczenia wag i biasów.\n",
    "        \"\"\"\n",
    "        E_data = np.zeros((self.no_v, self.no_h))  # Gradient na danych wejściowych\n",
    "        E_recon = np.zeros((self.no_v, self.no_h))  # Gradient na danych rekonstrukcji\n",
    "        E_bv_data = np.zeros((1, self.no_v))  # Biasy widoczne na danych wejściowych\n",
    "        E_bv_recon = np.zeros((1, self.no_v))  # Biasy widoczne na rekonstrukcji\n",
    "        E_bh_data = np.zeros((1, self.no_h))  # Biasy ukryte na danych wejściowych\n",
    "        E_bh_recon = np.zeros((1, self.no_h))  # Biasy ukryte na rekonstrukcji\n",
    "\n",
    "        for v in X:\n",
    "            v = v.reshape((1, -1))  # Przekształcenie danych wejściowych do formatu wektora\n",
    "            h_hat, pr_h = self.activate_hidden(v)  # Aktywacja warstwy ukrytej na danych wejściowych\n",
    "\n",
    "            # Obliczanie wartości gradientów dla danych wejściowych\n",
    "            E_bh_data += pr_h\n",
    "            E_bv_data += v\n",
    "            E_data += np.matmul(v.T, pr_h)\n",
    "\n",
    "            # Contrastive Divergence - krok rekonstrukcji\n",
    "            for _ in range(k):  # Wykonanie 'k' kroków CD\n",
    "                v, pr_v = self.activate_visible(h_hat)\n",
    "                h_hat, pr_h = self.activate_hidden(v)\n",
    "\n",
    "            # Obliczanie wartości gradientów dla rekonstrukcji\n",
    "            E_recon += np.matmul(v.T, pr_h)\n",
    "            E_bh_recon += pr_h\n",
    "            E_bv_recon += v\n",
    "\n",
    "        # Normalizacja gradientów przez liczbę próbek\n",
    "        E_data /= len(X)\n",
    "        E_recon /= len(X)\n",
    "        E_bh_data /= len(X)\n",
    "        E_bv_data /= len(X)\n",
    "        E_bh_recon /= len(X)\n",
    "        E_bv_recon /= len(X)\n",
    "\n",
    "        return E_data, E_recon, E_bv_data, E_bv_recon, E_bh_data, E_bh_recon\n",
    "\n",
    "    def fit(self, X, epochs=10, k=1, lr=0.01):\n",
    "        \"\"\"\n",
    "        Trenuje RBM na danych wejściowych X przez określoną liczbę epok.\n",
    "        \"\"\"\n",
    "        for e in range(epochs):\n",
    "            # Contrastive Divergence - obliczanie gradientów\n",
    "            Ed, Er, bvd, bvr, bhd, bhr = self.CD(X, k)\n",
    "\n",
    "            # Aktualizacja wag i biasów\n",
    "            self.W -= lr * (Er - Ed)\n",
    "            self.bias_h -= lr * (bhr - bhd).flatten()\n",
    "            self.bias_v -= lr * (bvr - bvd).flatten()\n",
    "\n",
    "            # Obliczanie błędu rekonstrukcji\n",
    "            test = self.recreate_error(X)\n",
    "            print(f\"Epoka {e + 1}: Błąd rekonstrukcji: {test[0]:.4f}, Energia: {test[1]:.4f}\")\n",
    "        return True\n",
    "\n",
    "    def recreate_error(self, X):\n",
    "        \"\"\"\n",
    "        Oblicza błąd rekonstrukcji i energię dla danych wejściowych.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        en = []\n",
    "        for v in X:\n",
    "            h, _ = self.activate_hidden(v)  # Aktywacja warstwy ukrytej\n",
    "            v_hat, _ = self.activate_visible(h)  # Rekonstrukcja warstwy widocznej\n",
    "            res.append(np.abs(v - v_hat))  # Błąd rekonstrukcji\n",
    "            en.append(\n",
    "                np.matmul(np.matmul(v, self.W), h) +\n",
    "                np.matmul(v, self.bias_v) +\n",
    "                np.matmul(h, self.bias_h)\n",
    "            )  # Obliczanie energii\n",
    "        res = np.array(res)\n",
    "        en = np.array(en)\n",
    "        return res.mean(), -en.mean()\n",
    "\n",
    "# Wczytanie danych MNIST\n",
    "(X, Y), (Xt, Yt) = mnist.load_data()\n",
    "X = X.reshape((X.shape[0], 28 * 28)).astype(float) / 255  # Normalizacja do zakresu [0, 1]\n",
    "X[X > 0.5] = 1  # Binarna konwersja (piksele powyżej 0.5 = 1)\n",
    "X[X <= 0.5] = 0  # Binarna konwersja (piksele poniżej 0.5 = 0)\n",
    "\n",
    "# Trening modelu RBM\n",
    "model = RBM(28 * 28, 100)  # Inicjalizacja modelu z 100 jednostkami ukrytymi\n",
    "model.fit(X, epochs=10, lr=0.01)  # Trening przez 10 epok\n",
    "\n",
    "# Rekonstrukcja obrazów\n",
    "j = 3  # Liczba obrazów do wyświetlenia\n",
    "k = 0\n",
    "for i in np.random.randint(0, len(X), j):\n",
    "    plt.subplot(j, 2, k * 2 + 1)\n",
    "    x, _ = model.activate_hidden(X[i])  # Aktywacja warstwy ukrytej\n",
    "    x, _ = model.activate_visible(x)  # Rekonstrukcja warstwy widocznej\n",
    "    x = x.reshape((28, 28))\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(j, 2, k * 2 + 2)\n",
    "    plt.imshow(X[i].reshape((28, 28)), cmap=\"gray\")  # Oryginalny obraz\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    k += 1\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
